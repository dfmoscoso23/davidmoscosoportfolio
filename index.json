[{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/contributions/deploy-triggers/","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"This talk looked at Liberty Mutual’s transformation to Continuous Integration, Continuous Delivery, and DevOps. For a large, heavily regulated industry, this task can not only be daunting, but viewed by many as impossible. Often, organizations try to reduce the friction through micro-fixes, but Eddie’s team asked how to change the culture to reduce the friction and concluded with the following final points:\n Don’t mandate DevOps. Give employees the chance to master their discipline with examples to set and follow. Favor deep end-to-end accomplishments over broad but incremental steps forward. Focus on taking the right teams far before encouraging broad adoption. Centralize the platforms and tools that your teams shouldn’t be thinking about. Provide foundational services/commodities and let teams stay on purpose. Incorporate contributions from everyone; don’t stifle autonomy. Stay open to new ways of working. Challenge security policies, but respect intentions. Find new ways to enforce concerns without abandoning precaution.    ","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/publications/alldaydevops/","tags":["DevOps","Continuous Integration","Continuous Delivery","CI/CD pipelines","agile","Culture"],"title":"Organically DevOps: Building Quality and Security into the Software Supply Chain at Liberty Mutual"},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README\u0026rsquo;s or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/contributions/shields-docker/","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client\u0026rsquo;s website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/contributions/schema-org/","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":"Intro Doesn\u0026rsquo;t matter whether it\u0026rsquo;s a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\n First it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026quot; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on.  Once you implement SSL certificates on your server you\u0026rsquo;ll want to require secure connections using Apache\u0026rsquo;s rewrite module. Now I won\u0026rsquo;t dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\n Creating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026quot; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users)  The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026lsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026lsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you\u0026rsquo;ll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You\u0026rsquo;ll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that\u0026rsquo;s easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You\u0026rsquo;ll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/blog/force-ssl/","tags":["apache","apache","redirect","rewrite","ssl","web development"],"title":"Forcing Visits to use SSL"},{"categories":null,"contents":"\u0026ldquo;BORT\u0026rdquo;is a structure of recognizing intentions for a Virtual Assistant.It combines the Neural Network BERT of Google and Naive Bayes Algorithms with CountVectorizer to understand the intention of the user.\nIn collaboration with:\n Adrián Cox Garzón Tomás González  GitHub Repository\nVirtual Assistant vs. Chatbot A chatbot is a simple bot who has commands to activate responses or functions. Our idea was to set a bot that can be integrated in a fluid conversational chat. The bot only interacts with others when it understands that the users need some help or want to listen a joke. To interact with it, it´s not necessary to summon it, because it is always listening and understanding. Because of this, it\u0026rsquo;s not just a bot it is a real virtual assistant who helps you whenever you need.\nBasic structure The structure of BORT is meant not only to be a chat bot it can be useful in some many ways, because it has a modular structure.\nWhen the input is recepted it pass for two layers to be understood. The first layer is a multilabel classification with multilingual BERT. The neural network was trained to recognize the basic intention of the input. When the basic intention is detected the input pass to another classification with CountVectorizer and a Naive Bayes Model. This model classifies in the semantics of the intention within the possible sections or answer to the intention preset for the VA. Then the VA acts according to the intention identified.\n MODELS Multilingual Classifier BERT BORT pre-classifies in four intentions: Informative, Requests, Questions, and Fun. Multilingual BERT was pretrained in 104 languages with the content of Wikipedia. Bert was pretrained without a label, it only was trained to predict the next sentence, or masked words. We trained MB with original phrases labeled with these intentions.\nNaive Bayes and CountVectorizer BERT is great finding the basic intention, but to process the semantics of the Phrase CountVectorizer works better. It vectorize the words and calculate the frequencies of the lemma with a TF-IDF calculus. The Naive Bayes model classifies into the multiple responses presets for that intention.\nThis division in two models makes BERT pay more attention in the syntax of the input and the Naive Bayes more in the Semantics. Combined can predict the intention of the user with an accuracy superior to 90%.\nAlfobot an instance of BORT We set a first instance of BORT in a Discord BOT. Alfobot was made in the image and likeness of Alfonso D. Blazquez a Data Science teacher. Alfobot have 13 functions related with learning Machine Learning and Deep Learning. It can help you providing code of the models or helping optimizing your model. One special feature of Alfobot is the jokes it can answer, because it was designed with a recommendation algorithm. Alfobot is now running freely in three Discord Servers.\nModels of Alfobot We trained BERT with all the conversation in a server of Discord. And the Naive Bayes with the same phrases but with the specific function associated with the phrase.\nThe recommendation algorithm extracts the lemmas of the words of each sentence of the input and search in the data base of possible answers. It creates a pool of phrases that matches a 80% of the lemmas. Then it selects the answer with a weighted random algorithm, where the weights are calculated with the historic response to that phrase. It takes into account how much the users laugh, the reactions and how much was used that phrase previously.\n","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/creations/bort_va/","tags":["Virtual Assistant","BERT","Naive Bayes","CountVectorizer","NLP","Bot","Discord"],"title":"BORT a Virtual Assistant - BOT"},{"categories":null,"contents":"GitHub Repository\nHow much time a new Data Scientist have to wait to find a Data Science Job? To answer this question, I analyzed more than one thousand LinkedIn profiles of Data Scientist who live in Madrid. The analysis focus on the academic backgrounds of the profiles and how much time past from the end of their Data Scientist Studies and his first Job as Data Scientist. Following this analyzes I made a model to know the probability of find a job in a period like the people who has the same academic background.\nThe Data Profiles: public information of LinkedIn of more than 1000 people self-defined as Data Scientist living in Madrid.\nAcademic Data of the Data Scientist in Madrid Only half of the Data Scientist has studied something related to Data:\n The Data Scientist has always another academic background different than Data Science:\n We can group the no-data-related background in Technical (Physics, Engineering), Mathematics (Math, Statistical),Humanities (Social Science, Philosophy, Psychology), Economics (Economy, Administration, Financial, Accounting), Marketing and Natural Sciences. And the distribution is like this:\n The types of the degrees are:\n Something to be noticed is that Data Scientist posted in average 4 items in his education section:\n Measurement of Job Search Time This project goal is predicting the time a person who studied something related with Data Science have to wait to find his first job in Data Science. For this this I calculated the time past for the end of the first Data related Studio and the start of the first job in Data Science, based in the LinkedIn information.\nAs I said, at first only the half of the profiles has a Data-related Study and now I find that only a quarter of the sample has studied Data and then find a Job in Data Science. In other words, a quarter of the profiles has a job of Data Science before of studied something related with data. This is because they are people who studied technical fields and know a lot of Data Science.\n Relation between academic background and the time of searching for a Data Science Job It\u0026rsquo;s not the same looking for a job of Data Science when you have a technical background than when you have a humanities background. It´s not the same have and Engineering degree than a bachelor’s degree. It´s not the same have a lot of academic Background, then only have studied Data Science. But this data impacts in the time of searching for a job? I believe it does. And that\u0026rsquo;s why I do this research.\nIn the following graphics we can see the possible relation between the Background and the time of looking for a job.\n It´s curious that the people who has studied Marketing and Economics has and average more time waiting for a job in Data Science. Probably because they can use Data Science in their own fields without the title.\n This graphic shows the relation between the number of Data Science studies and the time of finding you first job. The people who have more Studies waits more to find his first job in Data Science.\nThe Model The range of days was between -800 days and -15, expressed in negative numbers because it\u0026rsquo;s a subtraction. I decided binned in three groups: 0.8, 1.56 and 2.33 years to find a job. And the data is distributed like this:\n After testing several models, the best was a Random Forest Classifier. It was not a perfect model, but it had the best accuracy and F1 result. You can see a Confution Matrix:\n ","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/creations/ds_madrid/","tags":["Data Science","Jobs","linkedin","Machine Learning","EDA"],"title":"Data Science in Madrid"},{"categories":null,"contents":"As E-commerce coordinator of Editorial Losada, I had developed some tools to sync the bookstore Data-base and the API of Mercado Libre, for selling books. It automatizes the process of posting, and update stocks in the platform. It works like a Desktop tool.\n","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/creations/apimercadolibre/","tags":["Python","E-Commerce","SQL","Postgrees","Tkinter","API","Mercado Libre"],"title":"Develop a Client API for Mercado Libre and Editorial Losada"},{"categories":null,"contents":"Based on the Mercado libre clien api desktop tool, I develop a more generic API client for Woocommerce. It was usefull to sync stocks of the bookstore and the online shop in Woocommerce.\n","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/projects/creations/apiwoocommerce/","tags":["Python","E-Commerce","SQL","Postgrees","Tkinter","API","Woocommerce"],"title":"Develop a Client API for Woocommerce and Ultra Gestion"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://dfmoscoso23.github.io/davidmoscosoportfolio/search/","tags":null,"title":"Search Results"}]